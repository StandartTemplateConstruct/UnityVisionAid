# UnityHumanROS
Unity app that allows guidance of connected to it human via ROS messages

and runs `OpenMMLab` models on device *deployed by MMDeploy to ONNX Runtime*

and allows to open urls and QR codes visible in camera of the device

for [visually impaired](https://github.com/StandartTemplateConstruct/STVisualImpairmentAid)

for [unable to speak](https://github.com/StandartTemplateConstruct/STSpeechAid)

and other users of devices supported by `Unity`

in built-in browser of application

with on device `OpenMMLab` assisted labeling and cloud reinforcement learning

that supports on-device debugging and scripting

including `rdp://`

including `ssh://`

browser debugger `js` console ide

`jupyter` console ide - for working on `PyTorch` models
